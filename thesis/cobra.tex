\chapter{The Cobra tool}
\label{ch:cobra}

Development of a general tool for
  code-breaking game analysis
  and verification of feasibility and applicability of the suggested algorithms
  is an important part of this work.

We named the created tool Cobra, the \textbf{co}de-\textbf{br}eaking game \textbf{a}nalyser.
Input of the tool is a game specification in a special language, which
  we describe first.
Basic usage is explained afterwards with
  descriptions of various tasks the tool can perform with a given game.
Notes on dependencies on external tools,
  on extensibility of Cobra and
  some more implementation details
  are described in later sections.

Well-documented source codes of the tool, together with
  specifications of code-breaking games described in \autoref{ch:games}
  can be found in the electronic attachment of the thesis.
A git repository on GitHub\footnote{\url{http://www.github.com}}
  has been used during the development process,
  so another way of obtaining the source codes is by cloning
  the repository at \url{https://github.com/myreg/cobra}.
This website also serves as a homepage of the project, and contains
  all related documents.

Cobra is available under \emph{BSD 3-Clause License}\footnote{\url{http://opensource.org/licenses/BSD-3-Clause}},
  text of which is a part of the source codes.

\section{Input language} \label{sec:lng}

First, we describe the low-level language that is the input format of Cobra.
Then, the language is equipped with a preprocessor that allows
  macro generation of the low-lever language.

\subsection{Low-level language}

The low-level language is based directly on \autoref{def:game}, the formal definition of
  code-breaking games.
It is case-sensitive and whitespace is not significant at any position.

%\newcommand{\txt}[1]{\;\textcolor{DarkRed}{\textsc{#1}}\;}
\newcommand{\txt}[1]{\;\textsc{#1}\;}
\newcommand{\term}[1]{\;\textrm{#1}\;}

From a lexical point of view, there are three atoms.
Identifier (\symb{ident}), is a string starting with a letter or underscore
  that can contain letters, digits and underscores.
Integer (\symb{int}) is a sequence of digits.
String (\symb{string}) is a sequence of arbitrary characters enclosed in quotes.
Further, list of X (\symb{x-list}) is a comma-separated list of atoms of type X,
  generated by the grammar
  $$\msymb{x-list} ::= \msymb{x} \| \msymb{x-list}\;,\;\msymb{x}.$$

\begin{table}[t]
\begin{tabular}{|p{.4\textwidth}|p{.54\textwidth}|}
 \hline
\textsc{Variable} \symb{ident} &
    Declares a variable with a given identifier. \\
\textsc{Variables} \symb{ident-list} &
    Declares variables with given identifiers. \\
\textsc{Constraint} \symb{formula} &
    Defines the initial constraint $\init$. \\
\textsc{Alphabet} \symb{string-list} &
    Defines the parameter alphabet $\Sigma$. \\
\textsc{Mapping} \symb{ident} \symb{ident-list} &
    Defines a mapping with a given identifier.
    The seconds argument is a list of variable identifiers defining
      the values of the mapping for all elements of the alphabet.    \\
\textsc{Experiment} \symb{string} \symb{int} &
    Opens a section defining a new experiment named by the first argument
      and having the number of parameter given by the second argument.
    The section is closed automatically with a definition of a new experiment. \\
\textsc{Params-distinct} \symb{int-list} &
    Defines a restriction on the parameters of the experiment,
      requiring that parameters at specified positions are different.
    This is the only type of allowed restriction. \\
\textsc{Params-sorted} \symb{int-list} &
    Declares that the order of the parameters at specified positions
      is not important and, therefore
      only parametrizations where these parameters are sorted
      can be considered.
    This is not necessary for the game specification but can significantly
    improve the execution time. \\
\textsc{Outcome} \symb{string} \symb{formula} &
    Defines an outcome of the experiment named by the first argument. \\ \hline
\end{tabular} \medskip
\caption{Statements in the low-level language.}\label{tbl:lowlng}
\end{table}

A game specification is a sequence of statement on separate lines.
Supported statements are and their descriptions are listed in \autoref{tbl:lowlng}.
Valid values of \symb{formula} are defined by the grammar
\medskip
\begin{tabular}{rl}
 \symb{formula} ::=\;
    & \symb{ident$_1$} $\;\;\|\;\;$ ( \symb{formula} )
       $\;\;\|\;\;$ ! \symb{formula} \\
 $\|$ & \symb{formula} $\circ$ \symb{formula}
       $\;\;\|\;\;$ \texttt{X}-\symb{int$_1$} ( \symb{formula-list} ), \\
 $\|$ & \symb{ident$_2$} (\$ \symb{int$_2$} ),
\end{tabular}
\medskip

where \symb{ident$_1$} is an identifier of a variable
and $\circ\in\{$and, $\&$, or, $|\:$, --$>$, $<$--, $<$--$>\}$
is a standard logical operator with its usual meaning.

\texttt{X} is a \emph{numerical operator} $\atleast$, $\atmost$ or $\exactly$,
  explained in \autoref{sec:not}.
% Let $\form := \mathtt{X}$-$k(\form_1, ..., \form_n)$ be a formula,
%   $v$ a valuation of the variables and let $s$ be the number
%   of satisfied formulas among $\form_1, ...\form_n$ by valuation $v$.
% Then the formula $\form$ is satisfied by $v$ if and only
%   if $s>=k$, $s<=k$ and $s=k$,
%   for $X$ being $\atleast$, $\atmost$ and $\exactly$, respectively.
These operators are non-standard and could be cut out.
However, they are quite common and useful in specification of code-breaking games
  and their naive expansion to standard operators causes exponential
  expansion of the formula (with respect to $k$).
Hence we support these operators in the language and we handle
  them specifically during the transformation to the conjunctive normal form,
  avoiding the exponential expansion by introduction of new variables.
The conversion is described in detail in \autoref{s:cobra-sat}.

The last rule of the grammar describes application of a mapping on a parameter
  and is not allowed in the formula defining the initial constraint of the game.

\begin{example}
Recall the running example introduced in \autoref{ex:run1}.
The counterfeit-coin problem with four coins
 can be specified in the low-level language as follows.
\begin{lstlisting}
VARIABLES y, x1, x2, x3, x4
CONSTRAINT Exactly-1(x1, x2, x3, x4)
ALPHABET '1', '2', '3', '4'
MAPPING X x1, x2, x3, x4

EXPERIMENT 'weighing2x2' 4
  PARAMS_DISTINCT 1, 2, 3, 4
  OUTCOME 'lighter' ((X$1 | X$2) & !y) | ((X$3 | X$4) & y)
  OUTCOME 'heavier' ((X$1 | X$2) & y) | ((X$3 | X$4) & !y)
  OUTCOME 'same' !(X$1 | X$2 | X$3 | X$4)
\end{lstlisting}\eqed
\end{example}

To parse this language, we use a standard combination of
\emph{GNU Flex}\footnote{\url{http://flex.sourceforge.net/}} for lexical analysis and
\emph{GNU Bison}\footnote{\url{http://www.gnu.org/software/bison/}} for parser generation.
The exact LALR grammar we use can be found in the $\texttt{cobra.ypp}$ file
  in the source codes.

\subsection{Python preprocessing}

Although the low-level language is sufficient for code-breaking game specification,
  it is not very user-friendly and
  simple changes in a game may require extensive changes in the input file.
For example, if you want to change the number of coins in the counterfeit coin problem,
  you have to add or remove some experiment sections.

The situation is even worse in Mastermind, where the outcome formulas are
  generated by the algorithm described in \autoref{ex:form-mastermind}.
We would need to write a script to generate a specification of the game.

This is the reason why we suggest using a preprocessor.
As the demands of different games may significantly differ,
  we decided not to create a special preprocessing engine
  and use Python\footnote{\url{https://www.python.org}},
  a popular and intuitive scripting language, instead.

Now, the input can be an arbitrary Python script with calls to our extra functions
\textsc{Variable}, \textsc{Variables}, \textsc{Constraint}, \textsc{Alphabet},
\textsc{Mapping}, \textsc{Experiment}, \textsc{Params-distinct} and \textsc{Outcome},
which are directly mapped to the constructs in the low-level language.
The generation of the low-level language is carried out by execution of the Python file
  with those special function ingested.
The functions only print the corresponding low-level language constructs
  to an output file.
Types of their parameters are listed in \autoref{tbl:lngpy}.

\begin{table}
\begin{center}
\begin{tabular}{|l|c|c|}\hline
 \multicolumn{1}{|c|}{\textbf{Function}} & \textbf{Type of x} & \textbf{Type of y} \\\hline
\textsc{Variable}(x) & string & - \\
\textsc{Variables}(x) & list of strings & -\\
\textsc{Constraint}(x) & formula (as a string)& -\\
\textsc{Alphabet}(x) & list of strings & -\\
\textsc{Mapping}(x, y) & string & list of strings\\
\textsc{Experiment}(x, y) & string & integer \\
\textsc{Params-distinct}(x) & list of integers & -\\
\textsc{Params-sorted}(x) & list of integers & -\\
\textsc{Outcome}(x, y) & string & formula (as a string) \\\hline
\end{tabular}
\end{center}
\caption{Types of the extra functions allowed in the input files.}\label{tbl:lngpy}
\end{table}

\begin{example}
We show one possible way to specify the counterfeit coin problem in the
code snipped below.
\begin{lstlisting}[language=Python]
N = 12
x_vars = ["x" + str(i) for i in range(N)]
VARIABLES(["y"] + x_vars)
CONSTRAINT("Exactly-1(%s)" % ",".join(x_vars))
ALPHABET([str(i) for i in range(N)])
MAPPING("X", x_vars)

# Helper for generation of a disjunction of parameters
# For example, params(2,4) = "X$2 | X$3 | X$4"
params = lambda n0, n1: "|".join("X$" + str(i)
                                 for i in range(n0, n1 + 1))

for m in range(1, N//2 + 1):
  EXPERIMENT("weighing" + str(m), 2*m)
  PARAMS_DISTINCT(range(1, 2*m + 1))
  OUTCOME("lighter", "((%s) & !y) | ((%s) & y)" %
                     (params(1, m), params(m+1, 2*m)))
  OUTCOME("heavier", "((%s) & y) | ((%s) & !y)" %
                     (params(1, m), params(m+1, 2*m)))
  OUTCOME("same", "!(%s)" % params(1, 2*m))
\end{lstlisting}
\end{example}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Compilation and basic usage}

To compile Cobra, run \texttt{make} in the program folder.
This automatically compiles the external tools and builds the necessary libraries.
If everything finishes successfully,
  the binary executable \texttt{cobra-backend} is created
  and ready for being used.
If a problem occurs during the compilation, please refer to the \emph{Requirements}
paragraph of \autoref{sec:impl}.

The basic syntax to launch the tool is the following.

\medskip
\centerline{\texttt{./cobra [-m <mode>] [-s <sat solver>] [other options] <input file>}}
\medskip

The mode of operation, given with the \texttt{-m} switch,
  specifies the task that will be performed with a given game.
The four possible modes are described in \autoref{s:cobra-modes},
  together with descriptions
  of supplemental options for each mode.
The \texttt{-b} switch specifies a SAT solver that will be used for analysis of propositional formulas.
Details can be found in \autoref{s:cobra-sat}.

The main executable, \texttt{cobra}, is a Python script that preprocesses
  the input file and writes the low-level game specification to the \texttt{.cobra.in} file.
Then it executes \texttt{cobra-backend} and passes on all the options given
  by the user.
Therefore, you can run Cobra on a low-level input format by launching
  \texttt{cobra-backend} directly with the same syntax.

Before \texttt{cobra-backend} exits, it always outputs a \emph{time overview} section,
  with information on how much time have been spent on which operations and
  how many calls to the SAT solver and to the graph canonization tool have been made.

\begin{figure}[ht]
\begin{lstlisting}
===== TIME OVERVIEW =====
Total time: 74.68s
Bliss (calls/time): 1984 / 0.10s
SAT solvers         sat             fixed           models
* PicoSolver      59 / 0.09s     197  / 0.26s     5635 / 73.23s
\end{lstlisting}
\caption{An example of the time overview section.}
\label{fig:timeoverview}
\end{figure}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Modes of operation}\label{s:cobra-modes}

\subsection{Overview mode [o, overview] (default)}

\centerline{\texttt{./cobra -m overview <input file> }}
\medskip

Overview mode serves as a basic check that the input file is
  syntactically correct and that the specified game is sensible.
In this mode, the tool prints the basic information about the loaded game, such as
  the number of variables, the number of experiments, size of the search space,
  size of the preprocessed input file,
  trivial bounds on the worst-case and the average-case number of experiments and so on.

It also performs a \emph{well-formed check}, i.e. it verifies that the
  specified game is well-formed according to \autoref{def:wellformed}.
The algorithm for this purpose follows directly from \autoref{lma:well-formed}.
For each experiment, we verify that
  $\init->\exactlyk{1}(\formx_1, ..., \formx_k)$,
  where $\formx_1,...\formx_k$ are the outcomes of the experiment,
  is a tautology.
This is be done by negating the formula,
  passing it to a SAT solver, asking for satisfiability
  and expecting a negative result.

If a problem is found, the tool outputs an assignment and an experiment
  for which no outcome, or more that one outcome, is satisfied.

\begin{figure}[ht]
\begin{lstlisting}[xleftmargin=.2\textwidth]
Well-formed check... failed!
EXPERIMENT: weighing1 1 2
PROBLEMATIC ASSIGNMENT:
  TRUE: y x3
  FALSE: x1 x2 x4 x5 x6 x7 x8 x9 x10 x11 x12
\end{lstlisting}
\caption{An example of a failed well-formed check in the\\ counterfeit coin problem
 with no ``='' outcome.}
\end{figure}

\subsection{Simulation mode [s, simulation]}

\centerline{\texttt{./cobra -m simulation -e <strategy> -o <strategy> <input file> }}

In the simulation mode, you specify a strategy
  for the codebreaker (for experiment selection)
  and for the codemaker (for outcome selection).
This can be done using the \texttt{-e} and \texttt{-o} switches.

Here, the codemaker is not considered a player who chooses
  the secret code in the beginning and then only evaluates the experiments,
  but a player who chooses the outcomes
  of the experiments as they come according to his will.
The only condition is that the outcomes are consistent.

For the codebreaker, Cobra supports all one-step look-ahead strategies described in
\autoref{sec:oslas}: \texttt{max-models}, \texttt{exp-models},
 \texttt{ent-models}, \texttt{parts}, \texttt{min-fixed} and \texttt{exp-fixed}.
The codemaker can either use the strategy \texttt{models} that selects an outcome
  with the maximal number of models, or the strategy \texttt{fixed} that
  select an outcome with the minimal number of fixed variables.

Apart from these, the tool supports two extra options for both players,
  \texttt{interactive} and \texttt{random},
  which are not strategies in the sense of \autoref{def:strategy}.

If \texttt{interactive} is specified as the codebreaker's strategy,
  the tool prints a list of all experiments in each round
  and the user is asked
  to select an experiment from the list.
This effectively allows a user to play the game against a codemaker's strategy.
Similarly, if \texttt{interactive} is the codemaker's strategy, all possible outcomes
  are printed after each experiment and the user is asked to select one of them.
Unsatisfiable outcomes are printed as well but are marked accordingly
  and cannot be selected.
In the \texttt{random} mode, the experiment, or the outcome of an experiment, is
  chosen from the list at random.

The default values for both players are \texttt{interactive},
  so if you run the simulation mode without any further options,
  you will be first asked to select the experiment and then to select its outcome.

\subsection{Strategy analysis mode [a, analysis]}

\centerline{\texttt{./cobra -m analysis -e <strategy> <input file> }}

In the analysis mode, the tool computes
  the worst-case and
  the average-case number of experiments needed by
  a given codebreaker's strategy
  to reveal the secret valuation of the variables.
Supported strategies for the codebreaker are the same as in the simulation mode.

The algorithm for this task has been described in \autoref{alg:stganalysis}.
Two variants on the algorithm have been proposed,
  one with and one without symmetry detection.
By default, the symmetry detection in turned on
  but can be turned off with the \texttt{--no-symmetry} switch.

\subsection{Optimal strategy mode [ow, optimal-worst, oa, optimal-average]}

\centerline{\texttt{./cobra -m optimal-worst [--opt-bound <double>] <input file> }}
\centerline{\texttt{./cobra -m optimal-average [--opt-bound <double>] <input file> }}

In the optimal strategy mode, the tool computes the number
  of experiments needed by a worst-case optimal,
  or an average-case optimal strategy for a given code-breaking game.

The algorithm for this purpose has been described in \autoref{alg:acopt}.
An upper bound can be specified with \texttt{--opt-bound} switch.
In some cases, this can significantly speed up the process.

Note that the tool currently does not output the strategy in any format,
  it only computes the number of experiments needed by the optimal strategy.
Also note that the this task is currently very slow even for
  small instances of code breaking games.
Further optimizations would be necessary for the tool to synthesise the optimal
  strategy for Mastermind with 4 pegs and 6 colours in a reasonable time.
