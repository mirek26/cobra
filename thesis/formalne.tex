\chapter{Formal model}

\section{Notation and Terminology}
Let $\Form_\Var$ be the set of all prepositional formulas over
  the set of variables $\Var$;
  $\Val_\Var$ be the set of all valuations (boolean interpretation)
  of variables $\Var$.
Formulas $\form_0, \form_1 \in \Form_\Var$ are (semantically) equivalent,
  written $\form_0 \equiv \form_1$, if
  $\val(\form_0) = \val(\form_1)$ for all $\val\in\Val_\Var$.
We say that \emph{$\val$ is a model of $\form$}
  or that \emph{$\val$ satisfies $\form$}
  if $\val(\form) = 1$.


For a formula $\form\in\Form_\Var$, let
  $\numval_\Var{\form} = |\{ \val\in\Val_\Var \| \val(\form) = 1 \}|$
  be the number of models of $\form$ (valuations satisfying $\form$).
We often omit the index $\Var$ if it is clear from the context.

% For any unary predicate $P$, $\#i\in A.P(i) = |\{ i\in A \| P(i)\}|$.
%   We often omit the ``$\in A$'' part and write only $\#i.P(i)$
%   if the range of $i$ is clear from the context.

The set of all permutations of a set $\Var$ (bijections $\Var->\Var$)
  is denoted by $\Perm_\Var$ and
  $\idperm_\Var$ is the identity permutation.

%-------------------------------------------------------------------------------
% DEF: CODE BREAKING GAME
\section{Formal definition}

% Code breaking games are games between two players -- a \emph{codemaker}
%   and a \emph{codebreaker}.
% First, the codemaker chooses a secret code.
% Then the codebreaker successively performs experiments and collects partial
%   information about the code,
%   which is given by the codemaker according to the rules of the game.
% The codebreaker strives to reveal the code in minimal number of experiments.
% ... (introduction)

In this section, we formally define Code Breaking Games
  within the framework of propositional logic,
  where we represent the secret code as a valuation
  of propositional variables.
The game is represented as a \emph{set of variables},
  \emph{initial restriction} (a formula that is guaranteed to be satisfied),
  and a set of \emph{possible experiments}.
A finite set of possible \emph{outcomes} is associated with each experiment.
Outcome is a propositional formula that represents the partial information,
  which the codebreaker can gain from the experiment.

The number of experiments is typically very large
  (such as 36894 for the Counterfeit-coin Problem \ref{prob-coins})
  but most of them have same structure and yield similar outcomes.
Therefore we opt for a compact representation of an experiment as a pair
  (type of experiment, parametrization), where parametrization is a string
  over a defined alphabet.
This whole idea is formalized below.

\begin{definition}[Code Breaking Game] \label{def:game}
A \emph{Code Breaking Game} is a septuple
  $\game = (\Var, \init, \Expt, \Sigma, \Exp, F, \outcome)$, where
  \begin{itemize}
  \item $\Var$ is a finite set of propositional variables,
  \item $\init \in \Form_\Var$ is a satisfiable propositional formula,
  \item $\Expt$ is a finite set of types of experiments,
  \item $\Sigma$ is a finite alphabet,
  \item $\Exp \subseteq \Expt \times \Sigma^\star$
    is an \emph{experiment} relation, and
  \item $F$ is a finite collection of functions of type $\Sigma -> \Var$,
  \item $\outcome: \Expt -> 2^{\PForm_{\Var,F,\Sigma}}$ is an
  \emph{outcome function} such that $\outcome(\expt)$ is finite
  for any $\expt\in\Expt$. Definition of $\PForm$ follows
   (\autoref{def-pform}).
  \end{itemize}
\end{definition}

\begin{definition}[Parametrized formula] \label{def-pform}
A set of \emph{parametrized formulas} $\PForm_{\Var,F,\Sigma}$ is a set of
  all strings $\pform$ generated by the following grammar:
  $$ \pform ::= x \| f(\$n) \| \pform \circ \pform \| \neg \pform,$$
  where $x\in\Var$, $f\in F$, $n \in\Nset$,
  and $\circ\in\{\wedge, \vee, ==>\}$.
By $\pform(\param)$ we denote application of
  a parametrization $\param\in\Sigma^\star$
  on a formula $\pform$,
  which is defined recursively on the structure of $\pform$
  in the following way:
\begin{align}
(x)(\param) &= x, \\
(f(\$n))(\param) &= f(\param[n]),\\
(\pform_1\circ\pform_2)(\param) &= \pform_1(\param) \circ \pform_2(\param),\\
(\neg\pform)(\param) &= \neg(\pform(\param)).
\end{align}
\end{definition}

We use the special symbol $\$$ in $f(\$n)$ so that $n$ cannot be mistaken for
  the argument of $f$, which is $n$-th symbol of the parametrization.
Note that if $f(\$n)$ appears in $\pform$ and $|\param|<n$, then
  $\pform(\param)$ is undefined.

For the sake of simplicity, let us denote the set of possible outcomes for
  an experiment $\exp = (\expt, \param) \in \Exp$ by
  $\outcome(\exp) = \{ \pform(\param) \| \pform\in\outcome(\expt)\}$.

The compact representation with parametrized formulas does not restrict
  the class of games that can fit this definition.
If no two experiments
  can be united under the same type, every experiment can have its own type and
  allow only one possible parametrization.

\begin{definition}[Solving process]
An \emph{evaluated experiment} is a pair $(e, \form)$
  such that $\form\in\outcome(e)$.
Let us denote the set of evaluated experiments by $\Omega$.

A \emph{solving process} is a finite or infinite sequence
  of evaluated experiments.
\end{definition}

For simplicity, we omit the brackets around the pairs and write
  \[
  \proc = \exp_1, \form_1, \exp_2, \form_2, ...
  \]
Let
\begin{itemize}
\item $|\proc|$ denote the length of the sequence,
\item $\proc(k) = \exp_k$ denote the $k$-th experiment,
\item $\proc[k] = \form_k$ denote the $k$-th outcome,
\item $\proc[1..k] = \exp_1, \form_1, ..., \exp_k, \form_k$ denote the prefix of length $k$, and
\item $\aknow{\proc}{k} = \init \wedge \form_1 \wedge ... \wedge \form_k$
  denote the accrued knowledge after the first $k$ experiments
  (including the initial restriction $\init$). For finite $\proc$,
  let $\tknow{\proc} = \aknow{\proc}{|\proc|}$ be the overall accrued knowledge.
\end{itemize}

We denote by $\Vals = \{ \val\in\Val_\Var \| \val(\init) = 1 \}$ the set
  of valuations that satisfy $\init$ and
  by $\Formr = \{ \tknow{\proc} \| \proc\in\Omega^* \}$ the set of
  \emph{reachable formulas}.

Let us now describe the course of the game in the defined terms.
First, the codemaker choose a valuation $\val$ from $\Vals$.
Second, the codebreaker chooses a type $\expt\in\Expt$ and
  a parametrization $\param\in\Sigma^*$ such that $(\expt, \param)\in\Exp$.
Third, the codemaker gives the codebreaker a formula
  $\form\in\outcome((\expt, \param))$,
  which is satisfied by the valuation $\val$.
Then the evaluated experiment $((\expt, \param), \form)$ is appended to the
  (initially empty) solving process $\proc$ and they continue with
  the second step.
The game continues until $\numval{\tknow{\proc}} = 1$, which
  corresponds to the situation in which the codebreaker can uniquely
  determine the code.

So that the codemaker can always fulfill the third step,
  there must be a formula $\form\in\outcome(\exp)$ satisfied by any valuation.
Although it might make sense to allow multiple satisfied formulas, we restrict
  ourselves to games where the outcome is uniquely defined for given valuation.

\begin{definition}[Well-formed game] \label{def:wellformed}
A code-breaking game is \emph{well-formed} if for all $\exp \in \Exp$,
\begin{equation}
\forall\val\in\Vals.\;
  \exists \textrm{ exactly one }
     \form\in\outcome(\exp)\;.\; \val(\form) = 1
\end{equation}
\end{definition}

As the semantics of non-well-formed games is unclear,
  we focus only on well-formed games and, be default,
  we suppose a game to be well-formed if not stated otherwise.

%-------------------------------------------------------------------------------
% EXAMPLE: FAKE-COIN PROBLEM

\begin{example}[Fake-coin problem] \label{ex:form-fake-coin1}
Fake-coin problem with $n$ coins, one of which is fake, can be formalized as
a code breaking game
$\mathcal{F}_n = (\Var, \init, \Expt, \Sigma, \Exp, F, \outcome)$.

\begin{itemize}
\item
$\Var = \{x_1, x_2, ..., x_n, y\}$, \\
$\init = \exactly{1}\{x_1, ..., x_n\}$. \\
Intuitively, variable $x_i$ tells weather the coin $i$ is fake.
Variable $y$ tells weather it is lighter or heavier.
Formula $\init$ says that exactly one coin is fake.

\item
$\Expt = \{ w_2, w_4, ..., w_n \}$, \\
$\Sigma = \{1, 2,...,n\}$, \\
$\Exp = \bigcup_{1<=m<=n/2} \{ (w_{2m}, \param) \|
  \param \in \{1,...,n\}^{2m}, \forall x\in\Var. \#_x(\param)<=1 \}. $\\
There are $n/2$ types of experiment -- according to the number of coins we put on the weights.
The alphabet contains natural numbers up to $n$ and
possible parametrizations for $w_{2m}$ are strings of length $2m$ with no repetitions.

\item
$F = \{ f_x \}$, where $f_x(i) = x_i$ for $1 <= i <= n$, \\
$\outcome(w_m) = $ \vspace{-3mm}
\begin{align*}
  \big\{
& ((f_x(\$1) \vee ... \vee f_x(\$m)) \wedge \neg y) \vee ((f_x(\$m+1) \vee ... \vee f_x(\$2m)) \wedge y), \\
& ((f_x(\$1) \vee ... \vee f_x(\$m)) \wedge y) \vee ((f_x(\$m+1) \vee ... \vee f_x(\$2m)) \wedge \neg y), \\
& \neg (f_x(\$1) \vee ... \vee f_x(\$2m)) \big\}.
\end{align*}
There are 3 possible outcomes of every experiment.
First, the right side is heavier. This happens if the fake coin is lighter and it appears in the first half of the parametrization, or if it is heavier and it appears in the second half. Second, analogously, the left side is heavier.
Third, the weights are balanced if the fake coin do not participate in the experiment.
\end{itemize}
\end{example}

%-------------------------------------------------------------------------------
% EXAMPLE: FAKE-COIN PROBLEM - alternative

\begin{example}[Fake-coin problem, alternative] \label{ex:form-fake-coin2}
For demonstration purposes, here is another formalization of the same problem.
$\mathcal{F'}_n = (\Var, \init, \Expt, \Sigma, \Exp, F, \outcome)$.

\begin{itemize}
\item
$\Var = \{x_1, x_2, ..., x_n, y_1, y_2, ..., y_n\}$, \\
$\init = \exactly{1}\{x_1, ..., x_n, y_1, ..., y_n \}$. \\
Variable $x_i$ tells that the coin $i$ is lighter, variable $y_i$ tells that the coin $i$ is heavier.
Formule $\init$ says that exactly one coin is different.

\item
$\Expt, \Sigma, \Exp$ is defined as in \autoref{ex:form-fake-coin1}.

\item
$F = \{ f_x, f_y \}$, where $f_x(i) = x_i$ and $f_y(i) = y_i$ for $1 <= i <= n$, \vspace{-1.5mm}
\begin{flalign*}
\outcome(w_m) = \big\{ & (f_x(\$1) \vee ... \vee f_x(\$m)) \vee (f_y(\$m+1) \vee ... \vee f_y(\$2m)), & \\
& (f_y(\$1) \vee ... \vee f_y(\$m)) \vee (f_x(\$m+1) \vee ... \vee f_x(\$2m)), & \\
& \neg (f_x(\$1) \vee ... \vee f_x(\$2m) \vee f_y(\$1) \vee ... \vee f_y(\$2m)) \big\}. &
\end{flalign*}
\end{itemize}
\end{example}

%-------------------------------------------------------------------------------
% EXAMPLE: MASTERMIND 2

\begin{example}[Mastermind] \label{ex:form-mastermind2}
Mastermind puzzle with $n$ pegs and $m$ colors can be formalized as
a code breaking game
$\mathcal{M}_{n,m} = (\Var, \init, \Expt, \Sigma, \Exp, F, \outcome)$.

\begin{itemize}
\item
$\Var = \{x_{i,j} \| 1<=i<=n, 1<=j<=m \}$, \\
$\init = \bigwedge\left\{
  \exactly{1} \{x_{i,j} \| 1<=j<=m\} \| 1<=i<=n\right\}$. \\
Variable $x_{i,j}$ tells whether there is the color $j$ at position $i$.
Formula $\init$ says that there is exactly one color at each position.

\item
$\Expt = \{ g \}$,\\
$\Sigma = C$, \\
$\Exp = \{(g, \param) \| \param\in\Sigma^{n}\}$.\\
There is only one type of experiment,
  parametrization of which is any sequence of colors of length $n$.

\item
$F = \{ f_1, ..., f_n \}$, where $f_i(c) = x_{i,c}$ for $1<=i<=n$, \\
$\outcome(g) = \{ \textrm{Outcome}(b, w) \| 0<=b<=n, 0<=w<=n, b+w<=n \}$,
where $\textrm{Outcome}$ function is computed by the algorithm described below.
\end{itemize}

As described in the introduction of the Mastermind problem,
  the outcome corresponds to some maximal matching between the pegs
  in the code and in the guess.
The idea here is to generate all matchings corresponding to a given outcome,
  generate a formula that expresses validity
  of the matching for a given experiment and
  put them into a big disjunction.

The computation of Outcome $(b, w)$ works as follows.
First, we generate all the matchings. Let $P = \{1,2,..n\}$
  be the set of positions.
\begin{itemize}
\item Select $B\subseteq P$ such that $|B| = b$.
  These are the positions at which the color
  in the code and in the guess matches and
  they correspond to the black markers.
\item Select $W\subseteq P\times P$ such that $|W| = w$,
  $p_1(W)\cap B = \emptyset$, and $p_2(W)\cap B = \emptyset$,
  where $p_1, p_2$ are the projections.
  These correspond to the white markers -- $(i, j) \in W$ means that the color
  at position $i$ in the guess is at position $j$ in the code.
\end{itemize}

Next, for each combination $(B, W)$, we generate a conjunction
  in the following way:
\begin{itemize}
\item For $i\in B$, we add $f_i(\$i)$.
\item For $(i,j)\in W$, we add $\neg f_i(\$i) \wedge f_j(\$i)$.
\item For $(i,j)\in (P\setminus B\setminus p_1(W))
             \times (P\setminus B\setminus p_2(W))$, we add $\neg f_j(\$i)$.
  This guarantees that the matching is maximal.
\end{itemize}

The result is a disjunction of all these clauses, which effectively enumerates all the cases.
For example, for $n = 4$ the result of $\textrm{Outcome}(1, 1)$ starts with

\smallskip
\begin{scriptsize}$(
\neg f_0(\$0) \wedge \neg f_1(\$1) \wedge \neg f_1(\$2) \wedge
  \neg f_2(\$1) \wedge \neg f_2(\$2) \wedge f_3(\$3)) \vee
(\neg f_0(\$0) \wedge \neg f_0(\$1) \wedge \neg f_0(\$2) \wedge
  \neg f_1(\$0) \wedge \neg f_1(\$1) \wedge \neg f_2(\$1) \wedge
  \neg f_2(\$2) \wedge f_3(\$3)) \vee
(\neg f_0(\$0) \wedge \neg f_0(\$1) \wedge \neg f_0(\$2) \wedge
   \neg f_1(\$1) \wedge \neg f_1(\$2) \wedge \neg f_2(\$0) \wedge
   \neg f_2(\$2) \wedge f_3(\$3)) \vee
(\neg f_0(\$0) \wedge \neg f_0(\$2) \wedge \neg f_1(\$0) \wedge
  \neg f_1(\$1) \wedge \neg f_2(\$0) \wedge \neg f_2(\$1) \wedge
  \neg f_2(\$2) \wedge f_3(\$3)) \vee
(\neg f_0(\$0) \wedge \neg f_0(\$1) \wedge \neg f_1(\$1) \wedge
  \neg f_1(\$2) \wedge \neg f_2(\$0) \wedge \neg f_2(\$1) \wedge
  \neg f_2(\$2) \wedge f_3(\$3)) \vee
(\neg f_0(\$0) \wedge \neg f_0(\$1) \wedge \neg f_1(\$0) \wedge
  \neg f_1(\$1) \wedge \neg f_2(\$2) \wedge f_3(\$3)) \vee
(\neg f_0(\$0) \wedge \neg f_0(\$1) \wedge \neg f_1(\$0) \wedge
  \neg f_1(\$1) \wedge \neg f_1(\$2) \wedge \neg f_2(\$0) \wedge
  \neg f_2(\$2) \wedge f_3(\$3)) \vee
(\neg f_0(\$0) \wedge \neg f_0(\$2) \wedge \neg f_1(\$1) \wedge
  \neg f_2(\$0) \wedge \neg f_2(\$2) \wedge f_3(\$3)) \vee
(\neg f_0(\$0) \wedge \neg f_0(\$2) \wedge \neg f_1(\$0) \wedge
  \neg f_1(\$1) \wedge \neg f_1(\$2) \wedge \neg f_2(\$1) \wedge
  \neg f_2(\$2) \wedge f_3(\$3)) \vee ...,$
\end{scriptsize}

and contains 24 clauses at the top level with 144 literals in total.
\end{example}

%-------------------------------------------------------------------------------
% EXAMPLE: MASTERMIND

\begin{example}[Mastermind (alternative)] \label{ex:form-mastermind}
For completeness, we show another way to formalize the Mastermind problem,
  which does not need algorithmic generation of the formulas.
Let
  $\mathcal{M'}_{n,m} = (\Var, \init, \Expt, \Sigma, \Exp, F, \outcome)$.

\begin{itemize}
\item
$\Var$ and $\init$ is defined as in \autoref{ex:form-mastermind2}.
\item
$\Expt = \{ g_{k_1,...,k_m} \| k_i \in \{1,...,n\}, \sum_ik_i = n \}$,\\
$\Sigma = C$, \\
$\Exp = \{(g_{k_1,...,k_m}, \param) \| \param\in\Sigma^{n},
  \numpred{i}{\param[i]=j}=k_j\}$.\\
The type $g_{k_1,...,k_m}$ covers all the guesses in which the number of $j$-colored pegs is $k_j$.
Therefore, two guesses for which we use the same pegs (pegs are just shuffled) are of the same type,
but if we change a peg for one with different color, it is other type of experiment.

\item
$F = \{ f_1, ..., f_n \}$, where $f_i(c) = x_{i,c}$ for $1<=i<=n$,
\vspace{-2mm}
\begin{flalign}
\outcome(& g_{k_1,...,k_n}) =  \Big\{ &\\
 & \exactly{b}\{ f_i(\$i) \| 1<=i<=n \} \;\wedge & \label{eq:mm-blacks}\tag{1}\\
 & \exactly{t}\bigcup
      \big\{
           \{ \atleast{l}(x_{1,j},...,x_{n,j}) \| 1 <= l <= k_j \}
           \| 1<=j<=m
      \big\} & \label{eq:mm-whites}\tag{2}\\
  &\hspace{2cm} \| 0<=b<=t, 0<=t<=n\Big\}.
\end{flalign}
\end{itemize}

Part \eqref{eq:mm-blacks} of the formula captures the number of
  the black markers.
Part \eqref{eq:mm-whites} captures the total number of markers.
Indeed, we get $k$ markers for color $j$
  if and only if $k < k_j$ and there are
  at least $k$ pegs of color $j$ in the code, i.e. all the formulas
  $\atleast{i}(x_{1,j},...,x_{n,j})$ are satisfied for $i <= k$.
Note that since the number of pegs of each color is fixed by the type and we
  do not care about the exact positions, this part of the formula
  is not parametrized.

\end{example}

We do not provide the formal definition of other Code breaking Games presented in
  \autoref{ch:games}.
However, a computer language for game specification
  that is based on this formalism is introduced in \autoref{ch:cobra}, and
  definition of all the games in this language can be found in \autoref{app:games}.

%-------------------------------------------------------------------------------
% DEF: STRATEGY
\section{Strategies}

\begin{definition}[Strategy]
A \emph{strategy} is a function $\stg: \Omega^* -> \Exp$,
  determining the next experiment for a given finite solving process.
\end{definition}

A strategy $\stg$ together with a valuation $\val\in\Vals$
  induce an infinite solving process
  \[
  \procstg{\stg}{\val} = \exp_1, \form_1, \exp_2, \form_2, ...,
  \]
  where
  $\exp_{i+1} = \stg(\exp_1, \form_1, ..., \exp_i, \form_i)$
  and
  $\form_{i+1} \in \outcome(\exp_{i+1})$
  is such that
  $\val(\form_{i+1}) = 1$,
  for all $i\in\Nset$.
Note that thanks to the well-formed property,
  there is always exactly one such $\form_{i+1}$.

We define \emph{length} of a strategy $\stg$ on a valuation $\val$,
  denoted $\stglen{\stg}{\val}$,
  as the smallest $k\in\Nseto$ such that
  $\stgknow{\stg}{\val}{k}$ uniquely determines the code, i.e.
  \[
  \stglen{\stg}{\val} = \min \;\{ k\in\Nseto \| \numval{\stgknow{\stg}{\val}{k}} = 1 \}
  \]


The \emph{worst-case number of experiments} $\lenmax{\stg}$
  of a strategy $\stg$ is the maximal length of the strategy on a valuation $\val$,
  over all models $\val$ of $\form_0$, i.e.
  \[
  \lenmax{\stg} = \max_{\val\in\Vals} \stglen{\stg}{\val}.
  \]
We say that a strategy $\stg$ \emph{solves the game} if $\lenmax{\stg}$ is finite.
The game is \emph{soluble} if there exists a strategy that solves the game.

The \emph{average-case number of experiments} $\lenexp{\stg}$
  of a strategy $\stg$ is the expected number of experiments if the code
  is selected from models of $\init$ with uniform distribution, i.e.
  \[
  \lenexp{\stg} = \frac{
    \sum_{\val\in\Vals} \stglen{\stg}{\val}
    }{\numval{\init}}.
  \]
\medskip

\begin{definition}[Optimal strategy]
A strategy $\stg$ is \emph{worst-case optimal} if
  $\lenmax{\stg} <= \lenmax{\stg'}$ for any strategy $\stg'$.
A strategy $\stg$ is \emph{average-case optimal} if
  $\lenexp{\stg} <= \lenexp{\stg'}$ for any strategy $\stg'$.
\end{definition}

\begin{lemma}
Let $b = \max_{\expt\in\Expt} |\outcome(\expt)|$ be the maximal number of
  possible outcomes of an experiment. Then for every strategy $\stg$,
  \[
  \lenmax{\stg} >= \lceil \log_b(\numval{\init}) \rceil.
  \]
\end{lemma}

\begin{proof}
Let us fix a strategy $\stg$ and $k = \lenmax{\stg}$.
For an unknown model $\val$ of $\init$,
  $\stgknow{\stg}{\val}{k}$ can take up to
  $b^k$ different values.
By pidgeon-hole principle, if $\numval{\init} > b^k$, there must be a valuation
  $v$ such that $\numval{\stgknow{\stg}{\val}{k}} > 1$.
This would be a contradiction with $k = \lenmax{\stg}$ and, therefore,
  $\numval{\init} <= b^k$, which is equivalent with the statement of the lemma.
  \qed
\end{proof}

\begin{lemma} \label{lma:accruedknowledge}
Let $\stg$ be a strategy and let $\val_1, \val_2 \in\Vals$.
If $\val_1$ is a model of $\stgknow{\stg}{\val_2}{k}$,
  then $\procstg{\stg}{\val_1}[1..k] = \procstg{\stg}{\val_2}[1..k]$.
\end{lemma}

\begin{proof}
Let $\proc_1 = \procstg{\stg}{\val_1}$, $\proc_2 = \procstg{\stg}{\val_2}$
and consider the first place where $\proc_1$ and $\proc_2$ differs.
It cannot be an experiment $\proc_1(i) \not= \proc_2(i)$ as they are both
  values of the same strategy on the same process:
$\proc_1(i) = \stg(\proc_1[1..i-1]) =
              \stg(\proc_2[1..i-1]) = \proc_2(i)$.

Suppose it is an outcome of the $i$-th experiment, $\proc_1[i] \not= \proc_2[i]$
  and $i <= k$.
Since $\val_1$ satisfies $\aknow{\proc_2}{k}$ and $i <= k$,
  it satisfies $\proc_2[i]$ as well.
However, $\val_1$ always satisfies $\proc_1[i]$ and
  both $\proc_1[i]$ and $\proc_2[i]$ are from the set
  $\outcome(\proc_1(i)) = \outcome(\proc_2(i))$.
Since there is exactly one satisfied experiment for each valuation in the set,
  $\proc_1[i]$ and $\proc_2[i]$ must be the same.
Contradiction. \qed
\end{proof}

\begin{example} \label{ex:coin4-stg}
\TODO{Příklad jednoduché hry, strategie, odhadu pomocí lematu, optimální strategie.}
\end{example}

\subsection{Non-adaptive strategies}
\begin{definition}[Non-adaptive strategy]
A strategy $\stg$ is \emph{non-adaptive} if it decides the next experiment
  based on the length of the solving process only, i.e.
  whenever $\proc_1$ and $\proc_2$ are processes such that
  $|\proc_1| = |\proc_2|$,
  then
  $\stg(\proc_1) = \stg(\proc_2)$.

Non-adaptive strategies can be seen as functions $\stgx: \Nseto -> \Exp$.
Then $\stg(\proc) = \tau(|\proc|)$.
\end{definition}

Non-adaptive strategies corresponds to the well studied problems of
  static mastermind and
  non-adaptive strategies for the coutnerfeit coin problem \ref{} \ref{}.
We mention them here just to show the possibility of formulating these problems
  in our framework but we do not study them any further.

\subsection{Memory-less strategies}

\begin{definition}[Memory-less strategy]
A strategy $\stg$ is \emph{memory-less} if it decides the next experiment
  based on the accumulated knowledge only, i.e.
  whenever $\proc_1$ and $\proc_2$ are processes such that if
  $\tknow{\proc_1} \equiv \tknow{\proc_2}$
  then
  $\stg(\proc_1) = \stg(\proc_2)$.

Memory-less strategies can be considered as functions
  $\stgx: \Formr -> \Exp$ such that
  $\form_1\equiv\form_2 ==> \stgx(\form_1)=\stgx(\form_2)$.
Then $\stg(\proc) = \stgx(\tknow{\proc})$.
\end{definition}

\begin{lemma}
Let $\stg$ be a memory-less strategy and $\val\in\Vals$.
If there exists $k\in\Nset$ such that
  $\numval{\stgknow{\stg}{\val}{k}} = \numval{\stgknow{\stg}{\val}{k+1}}$,
 then
  $\numval{\stgknow{\stg}{\val}{k}} = \numval{\stgknow{\stg}{\val}{k+l}}$
 for any $l\in\Nset$.
\end{lemma}

\begin{proof}
For the sake of simplicity, let $\know^k = \stgknow{\stg}{\val}{k}$.
There is a formula $\form\in\outcome(\know^k)$,
  such that $\know^{k+1} \equiv \know^{k} \wedge \form$.
Therefore, if $\know^{k+1}$ is satisfied by valuation $\val$, so must be $\know^{k}$.
Since $\numval{\know^{k}} = \numval{\know^{k+1}}$, the sets of
  valuations satisfying $\know^{k}$ and $\know^{k+1}$ are exactly the same
  and the formulas are thus equivalent.
This implies $\stg(\know^{k}) = \stg(\know^{k+1})$ and $\know^{k+2} \equiv \know^{k+1}\wedge \form \equiv \know^{k+1}$.

By induction,
  $\stg(\know^{k+l}) = \stg(\know^{k})$ and
  $\know^{k+l} \equiv \know^{k}$
  for any $l\in\Nset$.\qed
\end{proof}

\begin{lemma}
Let $\stg$ be a strategy.
Then there exists a memory-less strategy $\stgx$ such that
  $\stglen{\stg}{\val} >= \stglen{\stgx}{\val}$ for all $\val\in\Vals$.
\end{lemma}

\begin{proof}
Let us choose any total order $\form_1, \form_2, ...$ of $\Formr$ such that
  if $\form_i$ implies $\form_j$, then $i <= j$.
We build a sequence of strategies $\stg_0, \stg_1, \stg_2, ...$ inductively in the following way.
Let $\stg_0 = \stg$.
\begin{itemize}
\item If there is no $v\in\Vals, k\in\Nseto$ such that
  $\stgknow{\stg_{i-1}}{v}{k} \equiv \form_i$, select any $\exp\in\Exp$ and
  define $\stg_i$ by
\[
\stg_i(\proc) = \left\{
 \begin{array}{lll}
 \stg_{i-1}(\proc)  & \textrm{ if } \tknow{\proc}\not\equiv\form_i,\\
 \exp               & \textrm{ if } \tknow{\proc}\equiv\form_i.
 \end{array}
 \right.
\]
Clearly, all induced solving processes for $\stg_i$ and $\stg_{i-1}$ are the same
  and $\stglen{\stg_i}{v} = \stglen{\stg_{i-1}}{v}$.

\item If there exists $v\in\Vals, k\in\Nseto$ such that
  $\stgknow{\stg_{i-1}}{v}{k} \equiv \form_i$, choose the largest $l$ such that
  $\stgknow{\stg_{i-1}}{v}{l} \equiv \form_i$ and define
\[
\stg_i(\proc) = \left\{
 \begin{array}{lll}
 \stg_{i-1}(\proc)            & \textrm{ if } \tknow{\proc}\not\equiv\form_i,\\
 \procstg{\stg_{i-1}}{v}(l)   & \textrm{ if } \tknow{\proc}\equiv\form_i.
 \end{array}
 \right.
\]
First we prove that this definition is correct.
Let $v_1, v_2, k_1, k_2$ be such that
  $\stgknow{\stg_{i-1}}{v_1}{k_1}\equiv\form_i\equiv\stgknow{\stg_{i-1}}{v_2}{k_2}$.
Take $l_1, l_2$ as the largest numbers such that
  $\stgknow{\stg_{i-1}}{v_1}{l_1}\equiv\form_i\equiv\stgknow{\stg_{i-1}}{v_2}{l_2}$.
Since $v_1$ satisfies $\stgknow{\stg_{i-1}}{v_2}{l_2}\equiv\form_i$,
  then $\procstg{\stg_{i-1}}{v_2}[1..l_2] = \procstg{\stg_{i-1}}{v_1}[1..l_2]$
  by \autoref{lma:accruedknowledge}.
The same holds for $l_1$ which means that $l_1 = l_2$ and
  $\procstg{\stg_{i-1}}{v_1}(l_1) = \procstg{\stg_{i-1}}{v_1}(l_2)$, which
  proves that the definition of $\stg_i$ is independent of the exact choices
  of $v$ and $k$.

Now $\stglen{\stg_i}{v} = \stglen{\stg_{i-1}}{v} - (l-k)$, where
  $k$ and $l$ is the smallest and the largest number such that
  $\stgknow{\stg_{i-1}}{v}{k}\equiv\form_i $ and
  $\stgknow{\stg_{i-1}}{v}{l}\equiv\form_i $, respectively,
  because
  $\procstg{\stg_{i-1}}{v}(l) = \procstg{\stg_{i}}{v}(k)$ and due to the ordering,
  the rest of the process is independent of the beginning.
\end{itemize}

The last strategy of the sequence is clearly memory-less and satisfies the
  condition in the lemma. \qed
\end{proof}

\begin{definition}[Greedy strategy]
Let $f: \Form_\Var -> \Zset$.
A memory-less strategy $\stg$ is \emph{$f$-greedy} if
  for every $\form\in\Form_X$ and $\exp'\in\Exp$,
\[
\max_{\formx \in \outcome(\stg(\form)) \atop \SAT{\form\wedge\formx}} f(\form\wedge\formx) <=
\max_{\formx \in \outcome(e) \atop \SAT{\form\wedge\formx}} f(\form\wedge\formx).
\]
In words, a greedy strategy minimizes
  the value of $f$ on the formula in the next step.
We say $\stg$ is \emph{greedy} if it is $\numval_\Var{}$-greedy.
\end{definition}

\begin{lemma}
Let $b = \max_{\expt\in\Expt} |\outcome(\expt)|$ be the maximal number of
  possible outcomes of an experiment.
If for any $\form\in\Formr$,
\[
  \exists\exp . \max_{\formx\in\outcome(\exp)} \numval{(\form\wedge\formx)} =
  \left\lceil \frac{\numval{\form}}{b} \right\rceil,
\]
then a greedy strategy $\stg$ is optimal and
\[
  \lenmax{\stg} = \lceil \log_b(\numval{\init}) \rceil.
\]
\end{lemma}

\begin{proof}
\TODO{Napsat důkaz.}
\end{proof}

\begin{example}
Greedy strategies are optimal in the fake-coin game $\mathcal{F}_n$.

\TODO{Napsat důkaz.}
\end{example}

% \begin{problem}
% Given a code-breaking game $\game$,
%   decide whether all greedy strategies are optimal.
% Hypothesis: It is the case for Fake-coin problem (?).
%   It is not the case for Mastermind[ref].
% \end{problem}

\input{game-symmetries}
\input{symmetry-breaking}
